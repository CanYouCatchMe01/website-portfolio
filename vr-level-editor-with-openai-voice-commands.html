<!DOCTYPE html><html lang="en-gb"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>VR level editor with OpenAI voice commands - Marcus Cazzola&#x27;s Portfolio</title><meta name="description" content="Details: The user can create, remove and duplicate objects with voice commandsüó£Ô∏è. The user can also move, rotate and scale&hellip;"><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="canonical" href="https://cazzola.click/vr-level-editor-with-openai-voice-commands.html"><link rel="alternate" type="application/atom+xml" href="https://cazzola.click/feed.xml"><link rel="alternate" type="application/json" href="https://cazzola.click/feed.json"><meta property="og:title" content="VR level editor with OpenAI voice commands"><meta property="og:image" content="https://cazzola.click/media/posts/9/scaleVRsmall.gif"><meta property="og:image:width" content="400"><meta property="og:image:height" content="300"><meta property="og:site_name" content="Marcus Cazzola's Portfolio"><meta property="og:description" content="Details: The user can create, remove and duplicate objects with voice commandsüó£Ô∏è. The user can also move, rotate and scale&hellip;"><meta property="og:url" content="https://cazzola.click/vr-level-editor-with-openai-voice-commands.html"><meta property="og:type" content="article"><link rel="shortcut icon" href="https://cazzola.click/media/website/upside_down_studios-removebg-preview.png" type="image/x-icon"><link rel="shortcut icon" href="https://cazzola.click/media/website/upside_down_studios-removebg-preview.png" type="image/x-icon"><link rel="stylesheet" href="https://cazzola.click/assets/css/style.css?v=3532e13fd0b9096d454aec3a49aa703f"><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://cazzola.click/vr-level-editor-with-openai-voice-commands.html"},"headline":"VR level editor with OpenAI voice commands","datePublished":"2023-03-27T15:20","dateModified":"2023-03-27T18:40","image":{"@type":"ImageObject","url":"https://cazzola.click/media/posts/9/scaleVRsmall.gif","height":300,"width":400},"description":"Details: The user can create, remove and duplicate objects with voice commandsüó£Ô∏è. The user can also move, rotate and scale&hellip;","author":{"@type":"Person","name":"Marcus Cazzola","url":"https://cazzola.click/authors/marcus-cazzola/"},"publisher":{"@type":"Organization","name":"Marcus Cazzola"}}</script></head><body class="lines"><div class="container lines lines--right"><header class="header"><a href="https://cazzola.click/" class="logo">Marcus Cazzola&#x27;s Portfolio</a><nav class="navbar js-navbar"><button class="navbar__toggle js-toggle" aria-label="Menu">Menu</button><ul class="navbar__menu"><li><a href="https://cazzola.click/tags/group-projects/" target="_self">Group Projects</a></li><li><a href="https://cazzola.click/tags/personal-projects/" target="_self">Personal Projects</a></li><li><a href="https://cazzola.click/about-me.html" target="_self">About Me</a></li></ul></nav></header><main class="main"><article class="post"><figure class="post__featured-image"><div class="post__featured-image__inner is-img-loading"><img src="https://cazzola.click/media/posts/9/scaleVRsmall.gif" loading="eager" height="300" width="400" alt=""></div></figure><header class="post__inner post__header"><h1 class="post__title">VR level editor with OpenAI voice commands</h1><div class="post__meta"><div class="post__meta__left"><a href="https://cazzola.click/authors/marcus-cazzola/" class="invert post__author" rel="author" title="Marcus Cazzola">Marcus Cazzola</a></div><div class="post__meta__right"><time datetime="2023-03-27T15:20" class="post__date">March 27, 2023</time><div class="post__updated">Updated on <time datetime="2023-03-27T15:20" class="post__date">March 27, 2023</time></div></div></div></header><div class="post__inner"><div class="post__entry"><p><strong style="font-family: var(--font-base); font-size: 1.125em; letter-spacing: var(--letter-spacing);">Details:</strong></p><ul><li style="font-weight: 400;" aria-level="1">VR level editor</li><li aria-level="1">Voice commands to create objects</li><li aria-level="1">Custom interaction system to move, rotate and scale objects</li><li aria-level="1">Using the game engine <a href="https://stereokit.net/Pages/Guides/Getting-Started.html" target="_blank" rel="noopener noreferrer">StereoKit </a>with C#</li><li><a href="https://github.com/CanYouCatchMe01/CreateWorldWithOpenAI" target="_blank" rel="noopener noreferrer">Github link</a></li></ul><p>The user can create, remove and duplicate objects with voice commands<span style="font-weight: 400;">üó£Ô∏è</span>. The user can also move, rotate and scale objects with his handsüñêÔ∏è. This was possible because I'm using OpenAI API<span style="font-weight: 400;">ü§ñ</span> to convert the spoken text to JSON which I can read at runtime.</p><p>In this video I create a snowman‚õÑ</p><div class="post__iframe"><iframe loading="lazy" width="560" height="315" src="https://www.youtube.com/embed/UThNc4y3I1Q" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen"></iframe></div><h4>What can the editor do?</h4><p>The user can create objects in the right and left hand.</p><pre><code>Voice command: Hey computer, create a red cube in my right hand and two blue spheres in left hand.</code></pre><figure class="post__image"><img loading="lazy" src="https://cazzola.click/media/posts/9/thumb-publii.gif" alt="" width="490" height="281"></figure><p>The user can duplicate and remove objects that he is grabbing</p><pre>Voice command: He computer remove the object I have in my right hand, but duplicates the one in my left hand</pre><figure class="post__image"><img loading="lazy" src="https://cazzola.click/media/posts/9/removeAndDuplicate.gif" alt="" width="486" height="273"></figure><p>The user can move, rotate and scale the objects. With the scaling coordinate system the user can choose to scale the object on all or just one axis.</p><figure class="post__image"><img loading="lazy" src="https://cazzola.click/media/posts/9/scaleVRsmall-2.gif" alt="" width="311" height="233"></figure><p>The AI supports very long voice commands.</p><pre>Voice command: Hey computer create 1 blue cube in my right hand 2 white sphere in my left hand 3 yellow cylinders in my right and 4 brown cubes in my left hand 5 blue cylinders in my right hand and 1 red cube in my left hand</pre><figure class="post__image"><img loading="lazy" src="https://cazzola.click/media/posts/9/handleManyCommands.gif" alt="" width="345" height="194"></figure><h4>How it works:</h4><h5 dir="auto" tabindex="-1">Game engine¬†</h5><p dir="auto">To display the VR world I use the open-source VR game engine StereoKit. Its main programming language is C#.</p><h5 dir="auto" style="margin-top: 2.28571rem; font-family: var(--font-base); font-weight: var(--font-weight-bold); letter-spacing: var(--letter-spacing);" tabindex="-1"><figure class="post__image"><img loading="lazy" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal); outline: 3px solid rgba(var(--color-primary-rgb), 0.55)  !important;" src="https://cazzola.click/media/posts/9/StereoKitWideBackground.svg" alt="" width="224" height="65"></figure></h5><h5 dir="auto" tabindex="-1">Convert speech to text¬†</h5><p>To convert the speech that the user says I use Microsoft's Azure Cloud speech-to-text service. There API works by that the user sends audio data over the internet and the API sends text back.</p><h5 dir="auto" style="margin-top: 2.28571rem; font-family: var(--font-base); font-weight: var(--font-weight-bold); letter-spacing: var(--letter-spacing);" tabindex="-1"><figure class="post__image"><img loading="lazy" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal); outline: 3px solid rgba(var(--color-primary-rgb), 0.55)  !important;" src="https://cazzola.click/media/posts/9/Microsoft_logo.svg" alt="" width="92" height="92"></figure></h5><h5 dir="auto" style="margin-top: 2.28571rem; font-family: var(--font-base); font-weight: var(--font-weight-bold); letter-spacing: var(--letter-spacing);" tabindex="-1">Convert text to JSON with OpenAI</h5><p>Open AI's text models are great at understanding text. By first giving the model some examples of what text it is suppose to generate, it manages to see patterns and can generate responses on text it has never seen before.</p><h5 dir="auto" style="margin-top: 2.28571rem; font-family: var(--font-base); font-weight: var(--font-weight-bold); letter-spacing: var(--letter-spacing);" tabindex="-1"><figure class="post__image"><img loading="lazy" style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal); outline: 3px solid rgba(var(--color-primary-rgb), 0.55)  !important;" src="https://cazzola.click/media/posts/9/OpenAI_Logo.svg" alt="" width="206" height="50"></figure>¬†</h5><p>Parts of my example text that I first give the model:</p><pre><strong>User:</strong> create three blue cube cubes and two white spheres on my left hand<br><strong>Assistant:</strong> {"add objects": [{"count": 3, "hand": "right", "shape": "cube", "color": {"r": 0.0, "g": 0.0, "b": 1.0}}, {"count": 2, "hand": "left", "shape": "sphere", "color": {"r": 1.0, "g": 1.0, "b": 1.0}}]}<br><strong>User:</strong> Remove the object in the right hand. Grabbing object with right hand<br><strong>Assistant:</strong> {"remove" : ["right"]}<br><strong>Support:</strong> Convert the user message to JSON. Only respond with the JSON object. Do not apologise or write any normal text</pre><figure class="post__image">Here is the code for generating an response for the AI.<br><img loading="lazy" src="https://cazzola.click/media/posts/9/generateAIResponce.png" alt="" width="365" height="171" sizes="(min-width: 37.5em) 1600px, 80vw" srcset="https://cazzola.click/media/posts/9/responsive/generateAIResponce-xs.png 384w, https://cazzola.click/media/posts/9/responsive/generateAIResponce-sm.png 600w, https://cazzola.click/media/posts/9/responsive/generateAIResponce-md.png 768w, https://cazzola.click/media/posts/9/responsive/generateAIResponce-lg.png 1200w, https://cazzola.click/media/posts/9/responsive/generateAIResponce-xl.png 1600w"></figure><h5 dir="auto" tabindex="-1">Interaction system to grab, rotate and scale.</h5><p>The StereoKit engine does not have and inbuild parenting system so I had to calculate own matrix math to parent the object to the hand and scale it. Here is some of the grabbing code.</p><figure class="post__image"><img loading="lazy" src="https://cazzola.click/media/posts/9/PtObjectSpace.png" alt="" width="458" height="60" sizes="(min-width: 37.5em) 1600px, 80vw" srcset="https://cazzola.click/media/posts/9/responsive/PtObjectSpace-xs.png 384w, https://cazzola.click/media/posts/9/responsive/PtObjectSpace-sm.png 600w, https://cazzola.click/media/posts/9/responsive/PtObjectSpace-md.png 768w, https://cazzola.click/media/posts/9/responsive/PtObjectSpace-lg.png 1200w, https://cazzola.click/media/posts/9/responsive/PtObjectSpace-xl.png 1600w"></figure><figure class="post__image"><img loading="lazy" src="https://cazzola.click/media/posts/9/GrabObjects-2.png" alt="" width="386" height="77" sizes="(min-width: 37.5em) 1600px, 80vw" srcset="https://cazzola.click/media/posts/9/responsive/GrabObjects-2-xs.png 384w, https://cazzola.click/media/posts/9/responsive/GrabObjects-2-sm.png 600w, https://cazzola.click/media/posts/9/responsive/GrabObjects-2-md.png 768w, https://cazzola.click/media/posts/9/responsive/GrabObjects-2-lg.png 1200w, https://cazzola.click/media/posts/9/responsive/GrabObjects-2-xl.png 1600w"></figure><figure class="post__image"><img loading="lazy" src="https://cazzola.click/media/posts/9/moveGrabedObjects.png" alt="" width="384" height="82" sizes="(min-width: 37.5em) 1600px, 80vw" srcset="https://cazzola.click/media/posts/9/responsive/moveGrabedObjects-xs.png 384w, https://cazzola.click/media/posts/9/responsive/moveGrabedObjects-sm.png 600w, https://cazzola.click/media/posts/9/responsive/moveGrabedObjects-md.png 768w, https://cazzola.click/media/posts/9/responsive/moveGrabedObjects-lg.png 1200w, https://cazzola.click/media/posts/9/responsive/moveGrabedObjects-xl.png 1600w"></figure><p>¬†</p><p>¬†</p></div><footer class="post__footer"><div class="post__tag-share"><div class="post__tag"><h3 class="post__tag__title">Posted in</h3><ul class="post__tag__list"><li><a href="https://cazzola.click/tags/personal-projects/">Personal Projects</a></li></ul></div><div class="post__share"></div></div></footer></div></article></main><footer class="footer"><div class="footer__left"><div class="footer__copy"></div></div><div class="footer__right"><div class="footer__social"><a href="https://www.linkedin.com/in/marcus-cazzola-b7a36b21b/" aria-label="LinkedIn" class="linkedin"><svg><use xlink:href="https://cazzola.click/assets/svg/svg-map.svg#linkedin"/></svg> </a><a href="https://www.youtube.com/channel/UCnN4U3AmF5i7RSw0tYV9I0g" aria-label="Youtube" class="youtube"><svg><use xlink:href="https://cazzola.click/assets/svg/svg-map.svg#youtube"/></svg></a></div></div><button onclick="backToTopFunction()" id="backToTop" class="footer__bttop" aria-label="Back to top" title="Back to top"><svg><use xlink:href="https://cazzola.click/assets/svg/svg-map.svg#toparrow"/></svg></button></footer></div><script>window.publiiThemeMenuConfig = { mobileMenuMode: 'sidebar', animationSpeed: 300, submenuWidth: 'auto', doubleClickTime: 500, mobileMenuExpandableSubmenus: true, relatedContainerForOverlayMenuSelector: '.navbar', };</script><script defer="defer" src="https://cazzola.click/assets/js/scripts.min.js?v=8190bbfcf662a6d5bf1ad35d88ad1ec9"></script><script>function publiiDetectLoadedImages () {
         var images = document.querySelectorAll('img[loading]:not(.is-loaded)');
         for (var i = 0; i < images.length; i++) {
            if (images[i].complete) {
               images[i].classList.add('is-loaded');
               images[i].parentNode.classList.remove('is-img-loading');
            } else {
               images[i].addEventListener('load', function () {
                  this.classList.add('is-loaded');
                  this.parentNode.classList.remove('is-img-loading');
               }, false);
            }
         }
      }
      publiiDetectLoadedImages();</script></body></html>