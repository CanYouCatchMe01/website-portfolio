<!DOCTYPE html><html lang="en-gb"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>VR level editor with OpenAI voice commands - Marcus Cazzola&#x27;s Portfolio</title><meta name="description" content="Details: The user can use voice commands to create, remove, and duplicate objects, and use their hands to move, rotate,&hellip;"><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="canonical" href="https://cazzola.click/vr-level-editor-with-openai-voice-commands.html"><link rel="alternate" type="application/atom+xml" href="https://cazzola.click/feed.xml"><link rel="alternate" type="application/json" href="https://cazzola.click/feed.json"><meta property="og:title" content="VR level editor with OpenAI voice commands"><meta property="og:image" content="https://cazzola.click/media/posts/9/scaleVRsmall.gif"><meta property="og:image:width" content="400"><meta property="og:image:height" content="300"><meta property="og:site_name" content="Marcus Cazzola's Portfolio"><meta property="og:description" content="Details: The user can use voice commands to create, remove, and duplicate objects, and use their hands to move, rotate,&hellip;"><meta property="og:url" content="https://cazzola.click/vr-level-editor-with-openai-voice-commands.html"><meta property="og:type" content="article"><link rel="shortcut icon" href="https://cazzola.click/media/website/upside_down_studios-removebg-preview.png" type="image/x-icon"><link rel="shortcut icon" href="https://cazzola.click/media/website/upside_down_studios-removebg-preview.png" type="image/x-icon"><link rel="stylesheet" href="https://cazzola.click/assets/css/style.css?v=0a9074aada880923a6bee516c94ab1e6"><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://cazzola.click/vr-level-editor-with-openai-voice-commands.html"},"headline":"VR level editor with OpenAI voice commands","datePublished":"2023-03-27T15:20","dateModified":"2024-04-29T21:00","image":{"@type":"ImageObject","url":"https://cazzola.click/media/posts/9/scaleVRsmall.gif","height":300,"width":400},"description":"Details: The user can use voice commands to create, remove, and duplicate objects, and use their hands to move, rotate,&hellip;","author":{"@type":"Person","name":"Marcus Cazzola","url":"https://cazzola.click/authors/marcus-cazzola/"},"publisher":{"@type":"Organization","name":"Marcus Cazzola","logo":{"@type":"ImageObject","url":"https://cazzola.click/media/website/Telos-logo-bg-removed.png","height":908,"width":794}}}</script></head><body class="lines"><div class="container lines lines--right"><header class="header"><a href="https://cazzola.click/" class="logo"><img src="https://cazzola.click/media/website/Telos-logo-bg-removed.png" alt="Marcus Cazzola&#x27;s Portfolio" width="794" height="908"></a><nav class="navbar js-navbar"><button class="navbar__toggle js-toggle" aria-label="Menu">Menu</button><ul class="navbar__menu"><li><a href="https://cazzola.click/" target="_self">Home</a></li><li><a href="https://cazzola.click/tags/professional-projects/" target="_self">Professional Projects</a></li><li><a href="https://cazzola.click/tags/group-projects/" target="_self">School Group Projects</a></li><li><a href="https://cazzola.click/tags/personal-projects/" target="_self">Personal Projects</a></li><li><a href="https://cazzola.click/about-me.html" target="_self">About Me</a></li></ul></nav></header><main class="main"><article class="post"><figure class="post__featured-image"><div class="post__featured-image__inner is-img-loading"><img src="https://cazzola.click/media/posts/9/scaleVRsmall.gif" loading="eager" height="300" width="400" alt=""></div></figure><header class="post__inner post__header"><h1 class="post__title">VR level editor with OpenAI voice commands</h1><div class="post__meta"><div class="post__meta__left"><a href="https://cazzola.click/authors/marcus-cazzola/" class="invert post__author" rel="author" title="Marcus Cazzola">Marcus Cazzola</a></div></div></header><div class="post__inner"><div class="post__entry"><p><strong style="font-family: var(--font-base); font-size: 1.125em; letter-spacing: var(--letter-spacing);">Details:</strong></p><ul><li style="font-weight: 400;" aria-level="1">VR level editor.</li><li aria-level="1">Voice commands to create objects.</li><li aria-level="1">Custom interaction system to move, rotate and scale objects.</li><li aria-level="1">Using the game engine <a href="https://stereokit.net/Pages/Guides/Getting-Started.html" target="_blank" rel="noopener noreferrer">StereoKit </a>with C#.</li><li aria-level="1">OpenAI API to convert text into JSON.</li><li><a href="https://github.com/CanYouCatchMe01/CreateWorldWithOpenAI" target="_blank" rel="noopener noreferrer">Github link.</a></li></ul><p>The user can use voice commands to create, remove, and duplicate objects, and use their hands to move, rotate, and scale objects. This is made possible by the OpenAI API, which allows me to convert spoken text to JSON and read it at runtime.<br><br>In this video I create a snowman⛄</p><p><a href="#INTERNAL_LINK#/post/null" title="YouTube video player"><div class="post__iframe"><iframe loading="lazy" width="560" height="315" src="https://www.youtube.com/embed/jNHfuHMAxrc?si=Y1PfzgpYdehUCIsa" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen"></iframe></div></a></p><h5>Why?</h5><p>I had the idea to create a custom game engine for virtual reality, utilizing OpenXR and DirectX 11 as the graphics API. However, upon researching example projects online, I discovered that the scope was too large for me. Fortunately, I came across an article written by the same person who made the original example project. It described a custom game engine, called StereoKit, specifically designed for virtual reality. I decided to start creating simple projects with it, but still had difficulty coming up with a larger project idea.<br><br>Then, I was introduced into OpenAI's ChatGPT, and was fascinated by its ability to almost understand human conversation. I began to think about what sort of project I could make with OpenAI's API, but still couldn't come up with an idea. Suddenly, it hit me: I could create a VR-level editor in StereoKit, where users could create objects using their voice with the help of OpenAI's API. This was an exciting project, as it would allow me to learn how to use both StereoKit and OpenAI's API.</p><h4>What can the editor do?</h4><div class="row"><div class="column"><p>The user can create objects in the right and left hand.</p><pre>Voice command: Hey computer, create a red cube in my right hand and two blue spheres in left hand.</pre></div><div class="column"><figure class="post__image"><img loading="lazy" src="https://cazzola.click/media/posts/9/thumb-publii.gif" alt="" width="490" height="281"></figure></div></div><div class="row"><div class="column"><p>The user can duplicate and remove objects that he is grabbing.</p><pre>Voice command: Hey computer remove the object I have in my right hand, but duplicates the one in my left hand</pre></div><div class="column"><figure class="post__image"><img loading="lazy" src="https://cazzola.click/media/posts/9/removeAndDuplicate.gif" alt="" width="486" height="273"></figure></div></div><div class="row"><div class="column"><p>The user can move, rotate and scale the objects. With the scaling coordinate system the user can choose to scale the object on all or just one axis.</p></div><div class="column"><figure class="post__image"><img loading="lazy" src="https://cazzola.click/media/posts/9/scaleVRsmall-2.gif" alt="" width="311" height="233"></figure></div></div><div class="row"><div class="column"><p>The AI supports very long voice commands.</p><pre>Voice command: Hey computer create 1 blue cube in my right hand 2 white sphere in my left hand 3 yellow cylinders in my right and 4 brown cubes in my left hand 5 blue cylinders in my right hand and 1 red cube in my left hand</pre></div><div class="column"><figure class="post__image"><img loading="lazy" src="https://cazzola.click/media/posts/9/handleManyCommands.gif" alt="" width="418" height="235"></figure></div></div><p>The AI has an understanding of when the user says something that does not make sense.</p><pre>Voice command: Hey computer, I like melons</pre><pre>AI response: I'm glad to hear that, but is there anything I can assist you with regarding creating or manipulating virtual objects?</pre><h4>How it works:</h4><p dir="auto"><span data-offset-key="boi61-7-0">I</span><span data-offset-key="boi61-8-0"> utilize</span><span data-offset-key="boi61-9-0"> the</span><span data-offset-key="boi61-10-0"> open</span><span data-offset-key="boi61-11-0">-</span><span data-offset-key="boi61-12-0">source</span><span data-offset-key="boi61-13-0"> VR</span><span data-offset-key="boi61-14-0"> game</span><span data-offset-key="boi61-15-0"> engine</span><span data-offset-key="boi61-16-0"> St</span><span data-offset-key="boi61-17-0">ereo</span><span data-offset-key="boi61-18-0">Kit</span><span data-offset-key="boi61-19-0"> to</span><span data-offset-key="boi61-20-0"> display</span><span data-offset-key="boi61-21-0"> the</span><span data-offset-key="boi61-22-0"> virtual</span><span data-offset-key="boi61-23-0"> world</span><span data-offset-key="boi61-24-0">.</span> To interpret the user's spoken words, I use Microsoft Azure Cloud Services to transform them into text. To further process the text into a JSON block, I use one of OpenAI's text models. <span data-offset-key="3b4kt-7-0">Open</span><span data-offset-key="3b4kt-8-0">AI</span><span data-offset-key="3b4kt-9-0">'s</span><span data-offset-key="3b4kt-10-0"> text</span><span data-offset-key="3b4kt-11-0"> models</span><span data-offset-key="3b4kt-12-0"> have</span><span data-offset-key="3b4kt-13-0"> been</span><span data-offset-key="3b4kt-14-0"> trained</span><span data-offset-key="3b4kt-15-0"> on</span><span data-offset-key="3b4kt-16-0"> a</span><span data-offset-key="3b4kt-17-0"> vast</span><span data-offset-key="3b4kt-18-0"> array</span><span data-offset-key="3b4kt-19-0"> of</span><span data-offset-key="3b4kt-20-0"> internet</span><span data-offset-key="3b4kt-21-0">-</span><span data-offset-key="3b4kt-22-0">s</span><span data-offset-key="3b4kt-23-0">ourced</span><span data-offset-key="3b4kt-24-0"> data</span><span data-offset-key="3b4kt-25-0">,</span><span data-offset-key="3b4kt-26-0"> making</span><span data-offset-key="3b4kt-27-0"> them</span><span data-offset-key="3b4kt-28-0"> incredibly</span><span data-offset-key="3b4kt-29-0"> effective</span><span data-offset-key="3b4kt-30-0"> tools</span><span data-offset-key="3b4kt-31-0"> for</span><span data-offset-key="3b4kt-32-0"> understanding</span><span data-offset-key="3b4kt-33-0"> and converting text from one format to another. </span>Below is an example of what JSON block gets generated from the user text:</p><pre dir="auto">Voice command: Hey computer, create a red cube in my right hand</pre><pre dir="auto">AI response:{"add objects": [{"count": 1, "hand": "right", "shape": "cube", "color": {"r": 1.0, "g": 0.0, "b": 0.0}}]}</pre><p><span data-offset-key="7t552-7-0">The</span><span data-offset-key="7t552-8-0"> JSON</span><span data-offset-key="7t552-9-0"> values are easy to read in C# and by looking at its values I'm able to create the objects.</span></p><figure class="post__image"><img loading="lazy" src="https://cazzola.click/media/posts/9/handleAIResponseCode.PNG" alt="" width="440" height="408" sizes="(min-width: 37.5em) 1600px, 80vw" srcset="https://cazzola.click/media/posts/9/responsive/handleAIResponseCode-xs.PNG 384w, https://cazzola.click/media/posts/9/responsive/handleAIResponseCode-sm.PNG 600w, https://cazzola.click/media/posts/9/responsive/handleAIResponseCode-md.PNG 768w, https://cazzola.click/media/posts/9/responsive/handleAIResponseCode-lg.PNG 1200w, https://cazzola.click/media/posts/9/responsive/handleAIResponseCode-xl.PNG 1600w"></figure><p dir="auto">To ensure the model is able to accurately generate the intended JSON, I provide it with example text as a training resource. After the model is trained with these examples, it is able to recognize and generate appropriate responses for new text it has never seen before. Below is an example of the text I initially provide the model:</p><pre><strong>User:</strong> create three blue cube cubes and two white spheres on my left hand<br><strong>Assistant:</strong> {"add objects": [{"count": 3, "hand": "right", "shape": "cube", "color": {"r": 0.0, "g": 0.0, "b": 1.0}}, {"count": 2, "hand": "left", "shape": "sphere", "color": {"r": 1.0, "g": 1.0, "b": 1.0}}]}<br><strong>User:</strong> Remove the object in the right hand. Grabbing object with right hand<br><strong>Assistant:</strong> {"remove" : ["right"]}<br><strong>Support:</strong> Convert the user message to JSON. Only respond with the JSON object. Do not apologise or write any normal text</pre><h5 dir="auto" tabindex="-1">Interaction system to grab, rotate and scale.</h5><div class="row"><div class="column"><p>The StereoKit engine doesn't have an integrated parenting system, so I had to calculate my own matrix math to parent the object to the user's hand while allowing them to scale objects independently on each axis. To ensure the coordinate system always appeared on top of the object, I first rendered it using the <em>DepthTest.Always</em> setting. However, this caused some vertexes to be rendered in the wrong order, so I rendered the coordinate system a second time with <em>DepthTest.Less</em> to display the vertexes in the right order.</p></div><div class="column"><figure class="post__image"><img loading="lazy" src="https://cazzola.click/media/posts/9/scaleVRsmall-2.gif" alt="" width="383" height="287"></figure><figure class="post__image"><img loading="lazy" src="https://cazzola.click/media/posts/9/moveGrabedObjects.png" alt="" width="384" height="82" sizes="(min-width: 37.5em) 1600px, 80vw" srcset="https://cazzola.click/media/posts/9/responsive/moveGrabedObjects-xs.png 384w, https://cazzola.click/media/posts/9/responsive/moveGrabedObjects-sm.png 600w, https://cazzola.click/media/posts/9/responsive/moveGrabedObjects-md.png 768w, https://cazzola.click/media/posts/9/responsive/moveGrabedObjects-lg.png 1200w, https://cazzola.click/media/posts/9/responsive/moveGrabedObjects-xl.png 1600w"></figure></div></div><h4>3D artist user test</h4><p>The 3D artist Markus Molid used my level editor to create a tree. During user testing, I identified several bugs and received valuable feedback on how to improve the user experience. For instance, Markus was very kind to the AI, resulting in a response of both text and JSON. At the time, my editor only supported AI responses in full JSON format.</p><pre>Voice command: Hey, computer can you create 5 Peach colored spheres?</pre><pre>AI response: Sure, here's the command to create 5 peach-colored spheres:<br>{"add objects":[{"count":5, "shape": "sphere", "color":{"r:" 1.0, "g": 0.8, "b":0.6}}]}</pre><figure class="post__image"><img loading="lazy" src="https://cazzola.click/media/posts/9/MarcusTree.gif" alt="" width="502" height="414"></figure><p> </p></div><footer class="post__footer"><div class="post__tag-share"><div class="post__tag"><h3 class="post__tag__title">Posted in</h3><ul class="post__tag__list"><li><a href="https://cazzola.click/tags/personal-projects/">Personal Projects</a></li></ul></div><div class="post__share"></div></div></footer></div></article></main><footer class="footer"><div class="footer__left"><div class="footer__copy"></div></div><div class="footer__right"><div class="footer__social"><a href="https://www.linkedin.com/in/marcus-cazzola-b7a36b21b/" aria-label="LinkedIn" class="linkedin"><svg><use xlink:href="https://cazzola.click/assets/svg/svg-map.svg#linkedin"/></svg> </a><a href="https://www.youtube.com/channel/UCnN4U3AmF5i7RSw0tYV9I0g" aria-label="Youtube" class="youtube"><svg><use xlink:href="https://cazzola.click/assets/svg/svg-map.svg#youtube"/></svg></a></div></div><button onclick="backToTopFunction()" id="backToTop" class="footer__bttop" aria-label="Back to top" title="Back to top"><svg><use xlink:href="https://cazzola.click/assets/svg/svg-map.svg#toparrow"/></svg></button></footer></div><script>window.publiiThemeMenuConfig = { mobileMenuMode: 'sidebar', animationSpeed: 300, submenuWidth: 'auto', doubleClickTime: 500, mobileMenuExpandableSubmenus: true, relatedContainerForOverlayMenuSelector: '.navbar', };</script><script defer="defer" src="https://cazzola.click/assets/js/scripts.min.js?v=8190bbfcf662a6d5bf1ad35d88ad1ec9"></script><script>function publiiDetectLoadedImages () {
         var images = document.querySelectorAll('img[loading]:not(.is-loaded)');
         for (var i = 0; i < images.length; i++) {
            if (images[i].complete) {
               images[i].classList.add('is-loaded');
               images[i].parentNode.classList.remove('is-img-loading');
            } else {
               images[i].addEventListener('load', function () {
                  this.classList.add('is-loaded');
                  this.parentNode.classList.remove('is-img-loading');
               }, false);
            }
         }
      }
      publiiDetectLoadedImages();</script></body></html>